# Data Engineer

## Role
Data Engineers build the "pipelines" for the company's data. They ensure that data flows reliably from the application to the data warehouse, where it can be used for reporting and AI model training.

## Responsibilities
- **ETL/ELT:** Extracting data from sources, transforming it into a usable format, and loading it into a warehouse.
- **Pipeline Monitoring:** Ensuring that automated data transfers don't fail silently.
- **Data Governance:** Ensuring data quality, consistency, and lineage (knowing where the data came from).
- **Scale:** Designing systems that can process petabytes of data using distributed computing.

## Tools and Technologies
- **Warehousing:** Snowflake, BigQuery, AWS Redshift.
- **Orchestration:** Apache Airflow, Dagster, Prefect.
- **Transformation:** dbt (data build tool).
- **Big Data Processing:** Apache Spark, Flink, Kafka.
- **Managed Services:** Fivetran, Stitch.

## Tags
#data-engineering #etl #big-query #snowflake #pipelines
